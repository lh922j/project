{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "• preprocessing.py\n",
    "# 전처리\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import chi2\n",
    "\n",
    "## 이상치 제거\n",
    "def mahalanobis(x, data):\n",
    "    x_minus_mu = x - np.mean(data, axis=0)\n",
    "    cov=np.cov(data,rowvar=False)\n",
    "    inv_covmat = np.linalg.inv(cov)\n",
    "    left_term = np.dot(x_minus_mu, inv_comat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()\n",
    "def outlier_detection(df):\n",
    "    range_q1, range_q3 = np.percentile(df['거리오차'],[25,75])\n",
    "    def_q1, def_q3 = np.percentile(df['표준편의'],[25,75])\n",
    "    range_iqr = range_q3 - range_q1\n",
    "    def_iqr = def_q3 - def_q1\n",
    "    range_lower = range_q1 - (range_iqr*1.5)\n",
    "    range_upper = range_q3 + (range_iqr*1.5)\n",
    "    def_lower = def_q1 - (def_iqr*1.5)\n",
    "    def_upper = def_q3 + (def_iqr*1.5)\n",
    "    \n",
    "    df_x = df[['거리오차','표준편의']].reset_index(drop=True)\n",
    "    \n",
    "    df_x['mahala'] = mahalanobis(x=df_x, data=df_x)\n",
    "    df_x['p_value'] = 1 - chi2.cdf(df_x['mahala'],1),\n",
    "    df_x['Outlier_maha'] = [\"outlier\" if x < 0.01 else \"normal\" for x in df_x['p_value']]\n",
    "    df_x['거리오차_이상치']=[\"outlier\" if (x< range_lower) or (x> range_upper) else \"normal\" for x in df_x['거리오차']]\n",
    "    df_x['표준편의_이상치']=[\"outlier\" if (x< def_lower) or (x> def_upper) else \"normal\" for x in df_x['표준편의']]\n",
    "\n",
    "    return df_x[['거리오차','표준편의','거리오차_이상치','표준편의_이상치','Outlier_maha']]\n",
    "                 \n",
    "def outlier(x):\n",
    "    temp_df = x[['거리오차', '표준편의']]\n",
    "    temp_df_outlier = outlier_detection(temp_df)\n",
    "    x = x.iloc[temp_df_outlier[(temp_df_outlier['Outlier_maha']=='normal')].index,:]\n",
    "    × = x.drop('편의오차',axis=1)\n",
    "    x = x.rename(columns={'표준편의 : 편의오차'})\n",
    "    return x\n",
    "\n",
    "## 풍향 숫자화\n",
    "def EtoN(X):\n",
    "    if isinstance(x, str):\n",
    "        char_mapping = {'N': 22.4, 'NE' : 67.4, 'E' : 112.4, 'SE': 157.4, 'S':202.4,'SW':247.4, 'W':292.4, 'NW' :337.4} \n",
    "        return char_mapping.get(x,x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# 데이터는 비문처리(군사자료는 비문!)\n",
    "df = pd.read_csv('함포.csv',index_col=None)\n",
    "\n",
    "# 격파사격(SALVO)만 사용\n",
    "df=df[df['사격종류']=='RF']\n",
    "df=df[df['사격방법']=='SALVO']\n",
    "a=df['편의오차'].astype(str)\n",
    "b=df['거리오차']\n",
    "\n",
    "# 편의, 거리오차 전처리\n",
    "for i in range(len(a)):\n",
    "    if '~' in a.iloc[i]:\n",
    "        a.iloc[i]='9999'\n",
    "    if a.iloc[i]=='-':\n",
    "        a.iloc[i]='9999'\n",
    "a=a.replace(to_replace=r'R', value='',regex=True)\n",
    "a=a.replace(to_replace=r'L', value='-', regex=True)\n",
    "a=a.replace(to_replace=r'HIT', value='0', regex=True) \n",
    "a=a.replace(to_replace=r'H', value='0', regex=True)\n",
    "a=a replace(to_replace=r'관측불가', value='9999', regex=True)\n",
    "\n",
    "for i in range(len(b)):\n",
    "    if b.iloc[i]=='-':\n",
    "        b.iloc[i]='9999'\n",
    "b=b.replace(to_replace=r',', value='', regex=True)\n",
    "b=b.replace(to_replace=r'Hit', value='0', regex=True)\n",
    "b=b.replace(to_replace=r'HIT', value='0', regex=True)\n",
    "b=b.replace(to_replace=r'H', value='0', regex=True)\n",
    "b=b.replace(to_replace=r'관측불가', value='9999', regex=True)\n",
    "a.astype(float) \n",
    "b.astype(float)\n",
    "df['편의오차']=a \n",
    "df['거리오차']=b \n",
    "\n",
    "# 사격거리 결측치 제거\n",
    "df=df[df['사격거리'].isna()!=True]\n",
    "# 풍향속 전처리\n",
    "df[['풍향','풍속']]=df['풍향속'].str.split('-', expand=True)\n",
    "df=df.drop(['풍향속'],axis= 1)\n",
    "df=df[df['풍향']!='NW/NE']\n",
    "df['풍향']=df['풍향'].map(EtoN)\n",
    "df['풍향']=df['풍향'].astype(float)\n",
    "\n",
    "# 파고 전처리\n",
    "df=df[(df['파고']!='0.5~1') & (df['파고']!='1~2') & (df['파고']!='1~1.5') & (df['파고']!='1.5~2') & (df['파고']!='1.4') & (df['파고']!='0.2') & (df['파고']!='-')] \n",
    "\n",
    "# 변수 선정 및 전처리\n",
    "df=df[['연 도','월 일','함 형','함포종류','풍향','풍속','파 고','사격거리','거리오차','편의오차','지정사거리']]\n",
    "df[['거리오차','편의오차','사격거리']] = df[['거리오차''편의오차','사격거리']].astype('float')\n",
    "df['풍속']= df['풍속'].astype('float')\n",
    "df = df[(df['풍속']<=15)]\n",
    "df127 = df[(df['함포종류']=='5inch')]\n",
    "df76 = df[(df['함포종류']=='76mm')]\n",
    "df40 = df[(df['함포종류']=='40mm')]\n",
    "df = pd.concat([df127,df76,df40],axis=0)\n",
    "\n",
    "# 이상치 제거\n",
    "df = df[(df['거리오차']!=9999) & (df['편의오차']!=9999)]\n",
    "# 표준편의 변환\n",
    "df['표준편의']= round(df['지정사거리']/df['사격거리']*df['편의오차'],2)\n",
    "df127 = df[df['함포종류']=='5inch']\n",
    "df76 = df[df['함포종류']=='76mm']\n",
    "df40 = df[df['함포종류']=='40mm']\n",
    "\n",
    "# 표준편의 기준 결측치 제거\n",
    "df40 = df40.dropna(subset=['표준편의'])\n",
    "\n",
    "# 이상치 제거\n",
    "df127 = outlier(df127)\n",
    "df40 = outlier(df40)\n",
    "df76 = outlier(df76)\n",
    "\n",
    "# 127mm, 76mm 데이터 결합\n",
    "df127['거리오차'] = df127['거리오차'].astype('float')\n",
    "df76['거리오차']= df76['거리오차'].astype('float')\n",
    "df = pd.concat([df127,df76], axis=0)\n",
    "\n",
    "# 함형별 묶기\n",
    "df_all = df[(df['함 형']=='DDH')|(df['함 형']=='FFG')|(df['함 형']=='PCC')|(df['함 형']=='PKG')]\n",
    "df_40 = df40[df40['함 형']=='PKM'] \n",
    "\n",
    "# 함형별 데이터, 종합\n",
    "df = pd.concat([df_all, df_40],axis=0)\n",
    "\n",
    "# 전달정확도 데이터 2가지로 나눠서 구성 (MPI : df1, PREC : df2)\n",
    "df[['거리오차','편의오차','사격거리']] = df[['거리오차', '편의오차' '사격거리']].astype('float')\n",
    "df1 = df.groupby(['연 도','월 일','함 형', '함포종류','풍향','풍속','파 고'])[['거리오차','편의오차']].mean()\n",
    "df1 = df1.rename(columns = {'거리오차':'MPI_Y','편의오차':'MPI_X'})\n",
    "df2 = df.groupby(['연 도','월 일','함 형', '함포종류','풍향','풍속','파 고'][['거리오차','편의오차']].std()\n",
    "df2 = df2.rename(columns = {'거리오차':'PREC_Y','편의오차':'PREC_X'})\n",
    "df1.reset_index(inplace=True)\n",
    "df2.reset_index(inplace=True)\n",
    "\n",
    "# 데이터 종합 후 전처리\n",
    "df1 = df1[['MPI_Y','MPI_X']]\n",
    "DA = pd.concat([df1,df2], axis=1)\n",
    "DA = DA.dropna()\n",
    "                 \n",
    "df1 = DA[['함 형','풍향','풍속','파 고','MPI_Y', 'MPI_X']]\n",
    "df2 = DA[['함 형','풍향','풍속','파고','PREC_Y','PREC_X']]\n",
    "\n",
    "df1 = df1.rename(columns= {'MPI_Y':'거리오차', 'MPI_X':'편의오차'})\n",
    "df2 = df2.rename(columns= {'PREC_Y':'거리오차', 'PREC_X':'편의오차'}) \n",
    "\n",
    "# 최종 Feature 선정\n",
    "df1 = df1[['함 형','풍향','풍속','파 고','거리오차']]\n",
    "df2 = df2[['함 형','풍향','풍속','파 고','편의오차']]\n",
    "\n",
    "# 전달정확도 데이터셋(MPI_거리,MPL편의, PREC_거리, PREC_편의)\n",
    "df_y1 = df1[['함 형','풍향','풍속','파 고','거리오차']]\n",
    "df_x1 = df1[['함 형','풍향','풍속','파 고','편의오차']]\n",
    "df_y2 = df2[['함 형','풍향','풍속','파 고','거리오차']]\n",
    "df_x2 = df2[['함 형','풍향','풍속','파 고','편의오차']]\n",
    "                 \n",
    "# 전달정확도 데이터 저장\n",
    "df_y1.to_csv('MPI_거리_raw.csv',index=False)\n",
    "df_x1.to_csv('MPI_편의_raw.csv',index=False)\n",
    "df_y2.to_csv('PREC_거리_raw.csv',index=False)\n",
    "df_x2.to_csv('PREC_편의_raw.csv',index=False)\n",
    "print('전처리 완료!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "• main.py\n",
    "import pandas as pd \n",
    "import os, random \n",
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "from ctgan \n",
    "import CTGAN from sklearn.cluster \n",
    "import KMeans from statsmodels.stats.outliers_influence \n",
    "import variance_inflation_factor from autogluon.tabular \n",
    "import TabularPredictor \n",
    "import time\n",
    "\n",
    "# 전처리 시작\n",
    "def main():\n",
    "    print(\"데이터를 선택합니다.\")\n",
    "    print(\"원하시는 번호를 입력해주세요.WnWn\")\n",
    "    print(\"1. MPI_거리\")\n",
    "    print(\"2. MPL편의\")\n",
    "    print(\"3. PREC_거리\")\n",
    "    print(\"4. PREC_편의\")\n",
    "    key= int(input(\"\\n\\n숫자만 입력하세요: \"))\n",
    "    \n",
    "    switch_dict={\n",
    "        1:\"MPI_거리\",\n",
    "        2:\"MPI_편의\",\n",
    "        3:\"PREC_거리\",\n",
    "        4:\"PREC_편의\",\n",
    "    }\n",
    "    result = switch_dict.get(key,\"잘못 입력하셨습니다.\")\n",
    "    print(f\"\\n\\n{key}. {result}를 선택하셨습니다.\")\n",
    "    return key, result\n",
    "# 회귀 시작\n",
    "def main2():\n",
    "    print(\"데이터의 종류를 선택합니다.\")\n",
    "    print(\"\\n\\n원하시는 번호를 입력해주세요.\")\n",
    "    print(\"1. RAW\")\n",
    "    print(\"2. AUG\")\n",
    "    print(\"3. 종료\")\n",
    "    key= int(input(\"\\n\\n숫자만 입력하세요: \"))\n",
    "    switch_dict={\n",
    "        1: \"df_raw\",\n",
    "        2: \"df_all\",\n",
    "        3:'회귀 종료'\n",
    "    }\n",
    "    result = switch_dict.get(key, \"잘못 입력하셨습니다.\")\n",
    "    if key ==1 or key==2:\n",
    "        print(f\"\\n\\n{result}의 성능평가를 시작합니다.\")\n",
    "    else:\n",
    "        print(\"\\n\\n종료합니다.\")\n",
    "    return key\n",
    "\n",
    "# 시드고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark=False \n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"PYTHONHASHSEED\"] =str(seed)\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"]=\"0\"\n",
    "# 풍향 군집화\n",
    "def WD(x):\n",
    "    kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "    pred = kmeans.fit_predict(x.reshape(-1,1))\n",
    "    ndf['풍향']=pred\n",
    "    df_wd = pd.get_dummies(ndf['풍향'], prefix='풍향')\n",
    "    wd_list=['풍향_O', '풍향_1', '풍향_2', '풍향_3', '풍향_4', '풍향_5', '풍향_6', '풍향_7']\n",
    "    return df_wd, wd_list\n",
    "\n",
    "# 거리오차\n",
    "def REP(rep, key):\n",
    "    if key==1:\n",
    "        n=8\n",
    "        r_list= ['거리_O', '거리_1', '거리_2', '거리_3','거리_4','거리_5', '거리_6', '거리_7']\n",
    "    else :\n",
    "        n=10\n",
    "        r_list=['거리_O', '거리_1', '거리_2', '거리_3', '거리_4','거리_5','거리_6','거리_7','거리_8','거리_9']\n",
    "        kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "        pred = kmeans.fit_predict(rep.reshape(-1,1))\n",
    "        ndf['거리오차']=pred\n",
    "        rep = pd.get_dummies(ndf['거리오차'], prefix='거리')\n",
    "        df_c=['DDH', 'FFG', 'PCC', 'PKG', 'PKM', '풍속', '풍향_0','풍향_1', '풍향_2', '풍향_3', '풍향_4','풍향_5', '풍향_6', '풍향_7', '파 고', 'ER', '거리오차']\n",
    "        return rep, _list, df_c, n\n",
    "\n",
    "# 편의오차\n",
    "def DEP(dep, key):\n",
    "    if key==2:\n",
    "        n=8\n",
    "        r_list=['편의_0', '편의_1', '편의_2', '편의_3', '편의_4', '편의_5', '편의_6', '편의_7']\n",
    "    else :\n",
    "        n=8\n",
    "        r_list=['편의_O', '편의_1', '편의_2', '편의_3', '편의_4', '편의_5', '편의_6', '편의_7']\n",
    "        kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "        pred = kmeans.fit_predict(dep.reshape(-1,1))\n",
    "        ndf['편의오차']=pred\n",
    "        dep = pd.get_dummies(ndf['편의오차'], prefix='편의')\n",
    "        df_c=['DDH', 'FFG', 'PCC', 'PKG', 'PKM', '풍속', '풍향_0', '풍향_1', '풍향_2', '풍향_3', '풍향 4', '풍향_5', '풍향_6', '풍향_7', '파 고', 'ER', '편의오차']\n",
    "        return dep, r_list, df_c, n\n",
    "# 풍향 개수 맞추기\n",
    "def wd_match(key):\n",
    "    # MPI_거리\n",
    "    wd_num=51\n",
    "    if key == 1:\n",
    "        m=df_raw['풍향_0'].value_counts().values.tolist()\n",
    "        df_O = df_aug[(df_aug['wd']=='풍향_0')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_1'].value_counts().values.tolist()\n",
    "        df_1 = df_aug[(df_aug['wd']=='풍향_1')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_2'].value_counts().values.tolist()\n",
    "        df_2 = df_aug[(df_aug['wd']=='풍향_2')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_3'].value_counts().values.tolist()\n",
    "        df_3 = df_aug[(df_aug['wd']=='풍향_3')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_4'].value_counts().values.tolist()\n",
    "        df_4 = df_aug[(df_aug['wd']=='풍향_4')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_5'].value_counts().values.tolist()\n",
    "        df_5 = df_aug[(df_aug['wd']=='풍향_5')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_6'].value_counts().values.tolist()\n",
    "        df_6 = df_aug[(df_aug['wd']=='풍향_6')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_7'].value_counts().values.tolist()\n",
    "        df_7 = df_aug[(df_aug['wd']=='풍향_7')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "    # MPI_편의\n",
    "    elif key == 2:\n",
    "        m=df_raw['풍향_0'].value_counts().values.tolist()\n",
    "        df_O = df_aug[(df_aug['wd']=='풍향_0')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_1'].value_counts().values.tolist()\n",
    "        df_1 = df_aug[(df_aug['wd']=='풍향_1')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_2'].value_counts().values.tolist()\n",
    "        df_2 = df_aug[(df_aug['wd']=='풍향_2')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_3'].value_counts().values.tolist()\n",
    "        df_3 = df_aug[(df_aug['wd']=='풍향_3')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_4'].value_counts().values.tolist()\n",
    "        df_4 = df_aug[(df_aug['wd']=='풍향_4')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_5'].value_counts().values.tolist()\n",
    "        df_5 = df_aug[(df_aug['wd']=='풍향_5')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_6'].value_counts().values.tolist()\n",
    "        df_6 = df_aug[(df_aug['wd']=='풍향_6')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_7'].value_counts().values.tolist()\n",
    "        df_7 = df_aug[(df_aug['wd']=='풍향_7')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "    # PREC_거리\n",
    "    elif key == 3:\n",
    "        m=df_raw['풍향_0'].value_counts().values.tolist()\n",
    "        df_O = df_aug[(df_aug['wd']=='풍향_0')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_1'].value_counts().values.tolist()\n",
    "        df_1 = df_aug[(df_aug['wd']=='풍향_1')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_2'].value_counts().values.tolist()\n",
    "        df_2 = df_aug[(df_aug['wd']=='풍향_2')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_3'].value_counts().values.tolist()\n",
    "        df_3 = df_aug[(df_aug['wd']=='풍향_3')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_4'].value_counts().values.tolist()\n",
    "        df_4 = df_aug[(df_aug['wd']=='풍향_4')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_5'].value_counts().values.tolist()\n",
    "        df_5 = df_aug[(df_aug['wd']=='풍향_5')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_6'].value_counts().values.tolist()\n",
    "        df_6 = df_aug[(df_aug['wd']=='풍향_6')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_7'].value_counts().values.tolist()\n",
    "        df_7 = df_aug[(df_aug['wd']=='풍향_7')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "    # PREC_편의\n",
    "    else :\n",
    "        m=df_raw['풍향_0'].value_counts().values.tolist()\n",
    "        df_O = df_aug[(df_aug['wd']=='풍향_0')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_1'].value_counts().values.tolist()\n",
    "        df_1 = df_aug[(df_aug['wd']=='풍향_1')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_2'].value_counts().values.tolist()\n",
    "        df_2 = df_aug[(df_aug['wd']=='풍향_2')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_3'].value_counts().values.tolist()\n",
    "        df_3 = df_aug[(df_aug['wd']=='풍향_3')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_4'].value_counts().values.tolist()\n",
    "        df_4 = df_aug[(df_aug['wd']=='풍향_4')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_5'].value_counts().values.tolist()\n",
    "        df_5 = df_aug[(df_aug['wd']=='풍향_5')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_6'].value_counts().values.tolist()\n",
    "        df_6 = df_aug[(df_aug['wd']=='풍향_6')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "        m=df_raw['풍향_7'].value_counts().values.tolist()\n",
    "        df_7 = df_aug[(df_aug['wd']=='풍향_7')].sample(n=wd_num-m[1],replace=True,random_state=42)\n",
    "    # RAW대비 개수 맞춰준 데이터 생성\n",
    "    df_a= pd.concat([df_0,df_1,df_2,df_3,df_4,df_5,df_6,df_7], axis=0)\n",
    "    return df_a\n",
    "\n",
    "## 산출물 함수\n",
    "def ST(x):\n",
    "    if x==0 :\n",
    "        st= pd.DataFrame({'DDH': [0],'FFG' :[0], 'PCC' : [0], 'PKG': [0], 'PKM': [1]})\n",
    "    elif x==1 :\n",
    "        st= pd.DataFrame({'DDH': [0],'FFG' :[0], 'PCC' : [0], 'PKG': [1], 'PKM': [0]})\n",
    "    elif x==2 :\n",
    "        st= pd.DataFrame({'DDH': [0],'FFG' :[0], 'PCC' : [1], 'PKG': [0], 'PKM': [0]})\n",
    "    elif x==3 :\n",
    "        st= pd.DataFrame({'DDH': [0],'FFG' :[1], 'PCC' : [0], 'PKG': [0], 'PKM': [0]})\n",
    "    else :\n",
    "        st= pd.DataFrame({'DDH': [1],'FFG' :[0], 'PCC' : [0], 'PKG': [1], 'PKM': [0]})\n",
    "    return st\n",
    "# 풍속\n",
    "def WS(x):\n",
    "    if x==0:\n",
    "        ws= pd.DataFrame({'풍속':[5]})\n",
    "    elif x==1:\n",
    "        ws= pd.DataFrame({'풍속':[8]})\n",
    "    elif x==2:\n",
    "        ws= pd.DataFrame({'풍속':[10]})\n",
    "    return ws\n",
    "# 파고\n",
    "def WV(x):\n",
    "    if x==0:\n",
    "        wv= pd.DataFrame({'파 고':[0.5]})\n",
    "    elif x==1:\n",
    "        wv= pd.DataFrame({'파 고':[1.0]})\n",
    "    else:\n",
    "        wv= pd.DataFrame({'파 고':[1.5]})\n",
    "    return wv\n",
    "# 풍향\n",
    "def WDD(x):\n",
    "    if x==2:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[0], '풍향_2':[1], '풍향_3' :[0], '풍향_4':[0], '풍향_5' :[0], '풍향_6' :[0], '풍향_7' :[0]})\n",
    "    elif x==4:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[0], '풍향_2':[0], '풍향_3' :[0], '풍향_4':[1], '풍향_5' :[0], '풍향_6' :[0], '풍향_7' :[0]})\n",
    "    elif x==7:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[0], '풍향_2':[0], '풍향_3' :[0], '풍향_4':[0], '풍향_5' :[0], '풍향_6' :[0], '풍향_7' :[1]})\n",
    "    elif x==0:\n",
    "        wd= pd.DataFrame({'풍향_0':[1], '풍향_1':[0], '풍향_2':[1], '풍향_3' :[0], '풍향_4':[0], '풍향_5' :[0], '풍향_6' :[0], '풍향_7' :[0]})\n",
    "    elif x==5:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[0], '풍향_2':[0], '풍향_3' :[0], '풍향_4':[0], '풍향_5' :[1], '풍향_6' :[0], '풍향_7' :[0]})\n",
    "    elif x==3:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[0], '풍향_2':[0], '풍향_3' :[1], '풍향_4':[0], '풍향_5' :[0], '풍향_6' :[0], '풍향_7' :[0]})\n",
    "    elif x==6:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[0], '풍향_2':[0], '풍향_3' :[0], '풍향_4':[0], '풍향_5' :[0], '풍향_6' :[1], '풍향_7' :[0]})\n",
    "    else:\n",
    "        wd= pd.DataFrame({'풍향_0':[0], '풍향_1':[1], '풍향_2':[0], '풍향_3' :[0], '풍향_4':[0], '풍향_5' :[0], '풍향_6' :[0], '풍향_7' :[0]})\n",
    "    return wd\n",
    "# 오차범위\n",
    "def DA(x, j): \n",
    "    global da, df_all\n",
    "    if x=='MPI_거리':\n",
    "        for i in range(j):\n",
    "            if i==0:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [1], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==1:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [1], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==2:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [1], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==3:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [1], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==4:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [1], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==5:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [1], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==6:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [1], f'{x[-2:]_7': [0]})\n",
    "            elif i==7:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [1]})\n",
    "            max = da.idxmax(axis=1)\n",
    "            e_r=pd.DataFrame()\n",
    "            e_r['ER']=max\n",
    "            da=e_r['ER']\n",
    "            new_row = pd.concat([gt,wd,ws,wv,da], axis=1)\n",
    "            df_all=pd.concat([df_all,pd.DataFrame(new_row, index=[0])])\n",
    "    elif x == 'MPI_편의':\n",
    "        for i in range(j):\n",
    "            if i==0:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [1], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==1:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [1], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==2:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [1], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==3:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [1], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==4:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [1], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==5:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [1], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==6:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [1], f'{x[-2:]_7': [0]})\n",
    "            elif i==7:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [1]})\n",
    "            max = da.idxmax(axis=1)\n",
    "            e_r=pd.DataFrame()\n",
    "            e_r['ER']=max\n",
    "            da=e_r['ER']\n",
    "            new_row = pd.concat([gt,wd,ws,wv,da], axis=1)\n",
    "            df_all=pd.concat([df_all,pd.DataFrame(new_row, index=[0])])\n",
    "    elif x=='PREC_거리':\n",
    "        for i in range(j):\n",
    "            if i==0:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [1], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==1:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [1], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==2:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [1], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==3:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [1], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==4:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [1], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==5:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [1], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==6:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [1], f'{x[-2:]_7': [0]})\n",
    "            elif i==7:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [1]})\n",
    "            max = da.idxmax(axis=1)\n",
    "            e_r=pd.DataFrame()\n",
    "            e_r['ER']=max\n",
    "            da=e_r['ER']\n",
    "            new_row = pd.concat([gt,wd,ws,wv,da], axis=1)\n",
    "            df_all=pd.concat([df_all,pd.DataFrame(new_row, index=[0])])\n",
    "    else :\n",
    "        for i in range(i):\n",
    "            if i==0:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [1], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==1:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [1], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==2:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [1], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==3:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [1], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==4:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [1], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==5:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [1], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [0]})\n",
    "            elif i==6:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [1], f'{x[-2:]_7': [0]})\n",
    "            elif i==7:\n",
    "                da=pd.DataFrame({f'{x[-2:]}_O' : [0], f'{x[-2:]_1' : [0], f'{x[-2:]_2' : [0], f'{x[-2:]_3' : [0], f'{x[-2:]_4' : [0], f'{x[-2:]_5': [0], f'{x[-2:]}_6': [0], f'{x[-2:]_7': [1]})\n",
    "            max = da.idxmax(axis=1)\n",
    "            e_r=pd.DataFrame()\n",
    "            e_r['ER']=max\n",
    "            da=e_r['ER']\n",
    "            new_row = pd.concat([gt,wd,ws,wv,da], axis=1)\n",
    "            df_all=pd.concat([df_all,pd.DataFrame(new_row, index=[0])])\n",
    "    return da\n",
    "# 시드고정\n",
    "seed_everything(42)\n",
    "start = time.time()\n",
    "# 시작\n",
    "while(1): \n",
    "    key, result = 0, 0\n",
    "    if __name__ == \"__main__\":\n",
    "        key, result = main()\n",
    "    # 데이터 불러오기\n",
    "    df_raw = pd.read_csv(f'{result}.csv',index_col=None)\n",
    "    print('\\n\\n데이터 증강을 시작합니다.')\n",
    "    # 데이터 증강\n",
    "    d_c=df_raw.columns\n",
    "    ctgan=CTGAN(epochs=50)\n",
    "    ctgan.fit(df_raw, d_c)\n",
    "    df_fake=ctgan.sample(1000)\n",
    "    print(df_fake.describe())\n",
    "    print(df_raw.describe())\n",
    "    df_new = pd.concat([df_raw,df_fake], axis=0, ignore_index=True)\n",
    "    print(df_new.info())\n",
    "    print(df_new)\n",
    "\n",
    "    # 증강데이터 사용\n",
    "    df = df_new\n",
    "    print(df.describe())\n",
    "\n",
    "    # 가데이터프레임\n",
    "    ndf = pd.DataFrame()\n",
    "    \n",
    "    # 함형\n",
    "    df_st = pd.get_dummies(df['함 형'])\n",
    "    print(df_st.columns)\n",
    "    # 풍향\n",
    "    wd = df['풍향'].to_numpy()\n",
    "    df_wd, wd_list=WD(wd)\n",
    "    # 풍속\n",
    "    ws = df['풍속']\n",
    "    # 파고\n",
    "    pago = df['파 고']\n",
    "    # DA\n",
    "    if key == 1 or key == 3:\n",
    "        rep = df['거리오차'].to_numpy()\n",
    "        da, r_list, df_c, cluster_num = REP(rep, key)\n",
    "        target = df['거리오차']\n",
    "    else :\n",
    "        dep = df['편의오차'].to_numpy()\n",
    "        da, r_list, df_c, cluster_num = DEP(dep, key)\n",
    "        target = df['편의오차']\n",
    "    # 학습데이터 생성\n",
    "    df_a=pd.concat([df_st, ws, df_wd, pago, da, target], axis=1)\n",
    "    print(df_a.info())\n",
    "    \n",
    "    df=df_a.astype(float)\n",
    "    # 전달정확도 개수 확인\n",
    "    df['ER']=0\n",
    "    for x in r_list:\n",
    "         for i, j in enumerate(df[x]):\n",
    "            if j == 1.0:\n",
    "                df['ER'][i]=x\n",
    "    # 풍향 개수 확인\n",
    "    df['wd']=0\n",
    "    for x in wd_list:\n",
    "         for i, j in enumerate(df[x]):\n",
    "            if j == 1.0:\n",
    "                df['wd'][i]=x\n",
    "\n",
    "\n",
    "    # RAW 데이터와 AUG데이터 분리\n",
    "    df_raw=df[:203]\n",
    "    df_aug=df[203:]\n",
    "    print('풍향 칼럼별 개수')\n",
    "    print('\\n\\nraw')\n",
    "    print(df_raw['wd'].value_counts())\n",
    "    print('\\n\\naug')\n",
    "    print(df_aug['wd'].value_counts())\n",
    "    # 풍향 개수 맞추기\n",
    "    df_a = wd_match(key)\n",
    "\n",
    "    # 데이터 합치기\n",
    "    df_all=pd.concat([df_a,df_raw], axis=0)\n",
    "    print('\\n\\n풍향 칼럼별 총합 개수 확인')\n",
    "    print(df_all['wd'].value_counts())\n",
    "    print('\\n\\n오차범주 확인')\n",
    "    print(df_all['ER'].value_counts())\n",
    "\n",
    "    df_all=df_all[df_c]\n",
    "    df_raw=df_raw[df_c]\n",
    "    df_all.to_csv(f'{result}_train.csv', encoding='utf-8',index=False)\n",
    "    df_raw.to_csv(f'{result}_raw.csv', encoding='utf-8',index=False)\n",
    "    print()\n",
    "    print(f'\\n\\n{len(df_all)}개의 전처리가 완료되었습니다.')\n",
    "\n",
    "    # 회귀시작\n",
    "    while(1):\n",
    "        if __name__ == \"__main__\":\n",
    "            reg_k = main2()\n",
    "            if reg_k==3:\n",
    "                ('\\n\\n종료합니다.')\n",
    "                break\n",
    "        print(f'{result} 회귀를 시작합니다.\\n\\n')\n",
    "        print('평가지표를 선택해주세요. :')\n",
    "        print('1. RMSE')\n",
    "        print('2. MAE')\n",
    "        print('3. R2')\n",
    "        z_list=['rmse', 'mae', 'r2']\n",
    "        z=int(input('숫자를 입력해주세요. : '))\n",
    "        \n",
    "\n",
    "        if reg_k == 1:\n",
    "            df_reg = pd.read_csv(f'{result}_raw.csv', index_col=None)\n",
    "            if key == 1 or key == 3:\n",
    "                reg = TabularPredictor(label='거리오차', eval_metric=z_list[z-1]).fit(df_reg,presets='best_quality', num_bag_folds=8)\n",
    "                ld_board=reg.leaderboard(df_reg, silent=True)\n",
    "                print(ld_board)\n",
    "            elif key == 2 or key == 4:\n",
    "                reg = TabularPredictor(label='편의오차', eval_metric=z_list[z-1]).fit(df_reg, presets='best_quality', num_bag_folds=8)\n",
    "                ld_board=reg.leaderboard(df_reg, silent=True)\n",
    "                print(ld_board)\n",
    "            print('\\n\\n성능평가 완료')\n",
    "        elif reg_k == 2 :\n",
    "              df_reg = pd.read_csv(f'{result}_train.csv',index_col=None)\n",
    "              if key == 1 or key == 3:\n",
    "                reg = TabularPredictor(label='거리오차', eval_metric=z_list[z-1]).fit(df_reg, presets='best_quality', num_bag_folds=8)\n",
    "                ld_board=reg.leaderboard(df_reg, silent=True)\n",
    "                print(ld_board)\n",
    "              elif key == 2 or key == 4:\n",
    "                reg = TabularPredictor(label='편의오차', eval_metric=z_list[z-1]).fit(df_reg, presets='best_quality', num_bag_folds=8)\n",
    "                ld_board=reg.leaderboard(df_reg, silent=True)\n",
    "                print(ld_board)\n",
    "            print('\\n\\n성능평가 완료')\n",
    "        break\n",
    "    if reg_k==1 or reg_k==3:\n",
    "         ('\\n\\n종료합니다.')\n",
    "         break\n",
    "    d_all=pd.DataFrame()\n",
    "    da = pd.DataFrame()\n",
    "    for i in range(0,5):\n",
    "        gt=ST(i)\n",
    "        for j in range(0,3): \n",
    "                ws = WS(j)\n",
    "                for k in range(0,8):\n",
    "                    wd=WDD(k)\n",
    "                    for l in range(0,3): \n",
    "                        wv=WV(l)\n",
    "                        da=DA(result, cluster_num)\n",
    "    predictions= reg.predict(df_all)\n",
    "    df_all['DA'] = predictions\n",
    "\n",
    "    gt_1=df_all[['DDH', 'FFG', 'PCC', 'PKG', 'PKM']]\n",
    "    max = gt_1.idxmax(axis=1)\n",
    "    df_all['함형'] = max\n",
    "\n",
    "    wd_1=df_all[['풍향_O', '풍향_1', '풍향_2','풍향_3', '풍향_4', '풍향_5', '풍향_6', '풍향_7']]\n",
    "    max = wd_1.idxmax(axis=1)\n",
    "    df_all['풍향']=max\n",
    "    df_sum = df_all[['함형','풍향', '풍속','파 고', 'ER', 'DA']]\n",
    "    print(df_sum.info())\n",
    "\n",
    "    df_sum.to_csv(f'{result}_pred.csv', encoding='utf-8',index=False)\n",
    "    print(f\"{result} 무기효과 산출 완료!\")\n",
    "    break\n",
    "end = time.time()\n",
    "print(f\"\\n\\n소요시간: {end-start:0.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "• result.py\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# cumulative_frequency 기준\n",
    "csv_1 = ['MPI_거리_pred.csv','MPI_편의_pred.csv','PREC_거리_pred.csv','PREC_편의_pred.csv']\n",
    "csv_2 = ['MPI_거리_raw.csv','MPI_편의_raw.csv','PREC_거리_raw.csv','PREC_편의_raw.csv']\n",
    "\n",
    "st= ['PKM', 'PKG', 'PCC', 'FFG', 'DDH']\n",
    "ws=[5, 8, 10] \n",
    "wv=[0.5, 1.0, 1.5]\n",
    "\n",
    "# 각각의 전달정확도 담을 튜플\n",
    "DA_list=[[],[],[],[]]\n",
    "\n",
    "for c in csv_1:\n",
    "    mpi_r=pd.read_csv(c, index_col=None)\n",
    "    for n in range(4): \n",
    "        if c==csv_1[n]:\n",
    "            # raw data 불러오기\n",
    "            cluster_value = pd.read_csv(csv_2[n], index_col=None)\n",
    "            for i in st:\n",
    "                if i == 'DDH' : \n",
    "                    for s in ws:\n",
    "                        for v in wv:\n",
    "                            val_sum=[]\n",
    "                            temp_val = 0\n",
    "                            all_da, da_n=0,0\n",
    "                            #RAW에서 최빈수 산출\n",
    "                            temp = cluster_value[(cluster_value[i]==1) & (cluster_value['파 고']==v) & (cluster_value['풍속']==s)]\n",
    "                            val_counts=temp['da'].value_counts()\n",
    "                            idx = val_counts.index.tolist()\n",
    "                            val = val_counts.values.tolist()\n",
    "                            \n",
    "                            for j in range(len(val)):\n",
    "                                temp = mpi_r[(mpi_r['함형']==i) & (mpi_r['파 고']==v) & (mpi_r['풍속']==s) & (mpi_r['da']==idx[j])]\n",
    "                                temp_val=round(temp['DA'].mean(),2) * val[j]\n",
    "                                val_sum.append(temp_val)\n",
    "                            if val != []:\n",
    "                                all_da=sum(val_sum)\n",
    "                                da_n=sum(val)\n",
    "                                mean_da=round(all_da/da_n,3)\n",
    "                            else :\n",
    "                                mean_da = np.nan\n",
    "                                DA_list[n].append(mean_da)\n",
    "                elif i == 'FFG':\n",
    "                    for s in ws:\n",
    "                        for v in wv:\n",
    "                            val_sum=[]\n",
    "                            temp_val = 0\n",
    "                            all_da, da_n=0,0\n",
    "                            #RAW에서 최빈수 산출\n",
    "                            temp = cluster_value[(cluster_value[i]==1) & (cluster_value['파 고']==v) & (cluster_value['풍속']==s)]\n",
    "                            val_counts=temp['da'].value_counts()\n",
    "                            idx = val_counts.index.tolist()\n",
    "                            val = val_counts.values.tolist()\n",
    "                            \n",
    "                            for j in range(len(val)):\n",
    "                                temp = mpi_r[(mpi_r['함형']==i) & (mpi_r['파 고']==v) & (mpi_r['풍속']==s) & (mpi_r['da']==idx[j])]\n",
    "                                temp_val=round(temp['DA'].mean(),2) * val[j]\n",
    "                                val_sum.append(temp_val)\n",
    "                            if val != []:\n",
    "                                all_da=sum(val_sum)\n",
    "                                da_n=sum(val)\n",
    "                                mean_da=round(all_da/da_n,3)\n",
    "                            else :\n",
    "                                mean_da = np.nan\n",
    "                                DA_list[n].append(mean_da)\n",
    "                elif i == 'PCC\":\n",
    "                    for s in ws:\n",
    "                        for v in wv:\n",
    "                            val_sum=[]\n",
    "                            temp_val = 0\n",
    "                            all_da, da_n=0,0\n",
    "                            #RAW에서 최빈수 산출\n",
    "                            temp = cluster_value[(cluster_value[i]==1) & (cluster_value['파 고']==v) & (cluster_value['풍속']==s)]\n",
    "                            val_counts=temp['da'].value_counts()\n",
    "                            idx = val_counts.index.tolist()\n",
    "                            val = val_counts.values.tolist()\n",
    "                            \n",
    "                            for j in range(len(val)):\n",
    "                                temp = mpi_r[(mpi_r['함형']==i) & (mpi_r['파 고']==v) & (mpi_r['풍속']==s) & (mpi_r['da']==idx[j])]\n",
    "                                temp_val=round(temp['DA'].mean(),2) * val[j]\n",
    "                                val_sum.append(temp_val)\n",
    "                            if val != []:\n",
    "                                all_da=sum(val_sum)\n",
    "                                da_n=sum(val)\n",
    "                                mean_da=round(all_da/da_n,3)\n",
    "                            else :\n",
    "                                mean_da = np.nan\n",
    "                                DA_list[n].append(mean_da)\n",
    "\n",
    "                elif i == 'PKG':\n",
    "                    for s in ws:\n",
    "                        for v in wv:\n",
    "                            val_sum=[]\n",
    "                            temp_val = 0\n",
    "                            all_da, da_n=0,0\n",
    "                            #RAW에서 최빈수 산출\n",
    "                            temp = cluster_value[(cluster_value[i]==1) & (cluster_value['파 고']==v) & (cluster_value['풍속']==s)]\n",
    "                            val_counts=temp['da'].value_counts()\n",
    "                            idx = val_counts.index.tolist()\n",
    "                            val = val_counts.values.tolist()\n",
    "                            \n",
    "                            for j in range(len(val)):\n",
    "                                temp = mpi_r[(mpi_r['함형']==i) & (mpi_r['파 고']==v) & (mpi_r['풍속']==s) & (mpi_r['da']==idx[j])]\n",
    "                                temp_val=round(temp['DA'].mean(),2) * val[j]\n",
    "                                val_sum.append(temp_val)\n",
    "                            if val != []:\n",
    "                                all_da=sum(val_sum)\n",
    "                                da_n=sum(val)\n",
    "                                mean_da=round(all_da/da_n,3)\n",
    "                            else :\n",
    "                                mean_da = np.nan\n",
    "                                DA_list[n].append(mean_da)\n",
    "                else :\n",
    "                    for s in ws:\n",
    "                        for v in wv:\n",
    "                            val_sum=[]\n",
    "                            temp_val = 0\n",
    "                            all_da, da_n=0,0\n",
    "                            #RAW에서 최빈수 산출\n",
    "                            temp = cluster_value[(cluster_value[i]==1) & (cluster_value['파 고']==v) & (cluster_value['풍속']==s)]\n",
    "                            val_counts=temp['da'].value_counts()\n",
    "                            idx = val_counts.index.tolist()\n",
    "                            val = val_counts.values.tolist()\n",
    "                            \n",
    "                            for j in range(len(val)):\n",
    "                                temp = mpi_r[(mpi_r['함형']==i) & (mpi_r['파 고']==v) & (mpi_r['풍속']==s) & (mpi_r['da']==idx[j])]\n",
    "                                temp_val=round(temp['DA'].mean(),2) * val[j]\n",
    "                                val_sum.append(temp_val)\n",
    "                            if val != []:\n",
    "                                all_da=sum(val_sum)\n",
    "                                da_n=sum(val)\n",
    "                                mean_da=round(all_da/da_n,3)\n",
    "                            else :\n",
    "                                mean_da = np.nan\n",
    "                                DA_list[n].append(mean_da)\n",
    "                                \n",
    "# 풍속, 파고별 데이터 생성\n",
    "alle=mpi_r[['함형','풍속','파 고']]\n",
    "alle=alle.rename(columns={'함형':'S.T',\"풍속':'Ws','파 고': 'Wv'})\n",
    "alle=alle.drop_duplicates(keep='last') \n",
    "alle=alle.reset_index(drop=True)\n",
    "                          \n",
    "alle['mpi_r']=DA_list[0]\n",
    "alle['mpi_d']=DA_list[1] \n",
    "alle['prec_r']=DA_list[2]\n",
    "alle['prec_d']=DA_list[3]\n",
    "\n",
    "# 파고 1 데이터\n",
    "alle=alle[(alle['Wv']==1.0)]\n",
    "print(alle.reset_index(drop=True))\n",
    "alle.to_csv('result.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
